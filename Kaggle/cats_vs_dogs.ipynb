{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e96d5e18-b9fc-478f-805c-86621d74b39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import shutil\n",
    "import torchvision as tv\n",
    "import torchvision.transforms as tt\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import ToPILImage\n",
    "from torch import nn as nn\n",
    "import numpy as np\n",
    "import time\n",
    "show = ToPILImage()\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70d1f4cc-106b-44d5-b59b-35f770f6912b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cat', 'Dog']\n"
     ]
    }
   ],
   "source": [
    "path = 'E:\\InteliJ Programes\\Pycharm\\dataset\\kaggle\\kagglecatsanddogs\\PetImages'\n",
    "labels = os.listdir(path)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ec43651-9204-49a7-8185-932addce9bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\InteliJ Programes\\Pycharm\\dataset\\kaggle\\kagglecatsanddogs\\dataset\\train\n"
     ]
    }
   ],
   "source": [
    "cat_path = os.path.join(path, 'Cat')\n",
    "dog_path = os.path.join(path, 'Dog')\n",
    "cats_vs_dogs_dataset_path = 'E:\\InteliJ Programes\\Pycharm\\dataset\\kaggle\\kagglecatsanddogs\\dataset'\n",
    "train_path = os.path.join(cats_vs_dogs_dataset_path, 'train')\n",
    "valid_path = os.path.join(cats_vs_dogs_dataset_path, 'valid')\n",
    "test_path = os.path.join(cats_vs_dogs_dataset_path, 'test')\n",
    "print(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c50473d1-1541-4758-b670-5afc19ac647d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dirs(): # 生成文件夹\n",
    "    if not os.path.isdir(cats_vs_dogs_dataset_path):\n",
    "        print('当前路径下不存在文件夹，现在创建文件夹')\n",
    "        os.mkdir(cats_vs_dogs_dataset_path)\n",
    "        os.mkdir(train_path)\n",
    "        os.mkdir(valid_path)\n",
    "        os.mkdir(test_path)\n",
    "        for i in enumerate(labels):\n",
    "            os.mkdir(os.path.join(train_path, i[1]))\n",
    "            os.mkdir(os.path.join(valid_path, i[1]))\n",
    "            os.mkdir(os.path.join(test_path, i[1]))\n",
    "        print(\"文件夹创建完成\")\n",
    "    else:\n",
    "        print(\"当前文件夹已存在\")\n",
    "        \n",
    "def check_dirs(): #检查文件夹是否都存在\n",
    "    print(f'{train_path}:{os.path.isdir(train_path)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b28e58f-c0a6-45e6-95fc-71864aac008a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前文件夹已存在\n"
     ]
    }
   ],
   "source": [
    "make_dirs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e77d2c4c-0d5f-4587-b44d-ba1cc55b102f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据集文件复制到train、valid、test文件夹下\n",
    "\n",
    "def load_train_images(n=7500):\n",
    "    fnames = ['{}.jpg'.format(i) for i in range(n)]\n",
    "    for i in enumerate(labels):\n",
    "        for fname in fnames:\n",
    "            src = os.path.join(os.path.join(path, i[1]), fname)\n",
    "            dst = os.path.join(os.path.join(train_path, i[1]), fname)\n",
    "            shutil.copyfile(src, dst)\n",
    "            \n",
    "def load_valid_images():\n",
    "    fnames = ['{}.jpg'.format(i) for i in range(7500,10625)]\n",
    "    for i in enumerate(labels):\n",
    "        for fname in fnames:\n",
    "            src = os.path.join(os.path.join(path, i[1]), fname)\n",
    "            dst = os.path.join(os.path.join(valid_path, i[1]), fname)\n",
    "            shutil.copyfile(src, dst)\n",
    "            \n",
    "def load_test_images():\n",
    "    fnames = ['{}.jpg'.format(i) for i in range(10625,12450)]\n",
    "    for i in enumerate(labels):\n",
    "        for fname in fnames:\n",
    "            src = os.path.join(os.path.join(path, i[1]), fname)\n",
    "            dst = os.path.join(os.path.join(test_path, i[1]), fname)\n",
    "            shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f103f0ac-078d-4ea4-bf48-b4779f550b02",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 检测是否有失效图片\n",
    "from PIL import Image\n",
    "folder_path = r'E:\\InteliJ Programes\\Pycharm\\dataset\\kaggle\\kagglecatsanddogs\\dataset\\valid'\n",
    "extensions = []\n",
    "for fldr in os.listdir(folder_path):\n",
    "    sub_folder_path = os.path.join(folder_path, fldr)\n",
    "    print(sub_folder_path)\n",
    "    for filee in os.listdir(sub_folder_path):\n",
    "        file_path = os.path.join(sub_folder_path, filee)\n",
    "        print('** Path: {}  **'.format(file_path), end=\"\\r\", flush=True)\n",
    "        im = Image.open(file_path)\n",
    "        rgb_im = im.convert('RGB')\n",
    "        if filee.split('.')[1] not in extensions:\n",
    "            extensions.append(filee.split('.')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f98d740e-b59b-4c16-b011-d3fe5530774f",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_train_images()\n",
    "load_valid_images()\n",
    "load_test_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71085c65-2573-4168-9b02-baf68e319fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tsfm = tt.Compose([\n",
    "                    tt.ToTensor(),\n",
    "                    tt.Resize((128, 128)),\n",
    "                    tt.RandomHorizontalFlip(),\n",
    "                    #tt.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                    ])\n",
    "valid_test_tsfm = tt.Compose([\n",
    "                    tt.ToTensor(),\n",
    "                    tt.Resize((128, 128)),\n",
    "                    #tt.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dca19cdd-6da4-409a-b6c0-24c38941241d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ImageFolder(\n",
    "                        root=train_path,\n",
    "                        transform=train_tsfm)\n",
    "valid_dataset = ImageFolder(\n",
    "                        root=valid_path,\n",
    "                        transform=valid_test_tsfm)\n",
    "test_dataset = ImageFolder(\n",
    "                        root=test_path,\n",
    "                        transform=valid_test_tsfm)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "                    dataset=train_dataset,\n",
    "                    batch_size=32,\n",
    "                    shuffle=True,\n",
    "                    num_workers=2\n",
    "                    )\n",
    "valid_loader = torch.utils.data.DataLoader(\n",
    "                    dataset=valid_dataset,\n",
    "                    batch_size=32,\n",
    "                    shuffle=False,\n",
    "                    num_workers=2\n",
    "                    )\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "                    dataset=test_dataset,\n",
    "                    batch_size=32,\n",
    "                    shuffle=False,\n",
    "                    num_workers=2\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9ca3408-b79e-4f9b-9d5d-5e6e1a8e460b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dog\n",
      "tensor([[[0.3213, 0.3951, 0.2514,  ..., 0.3826, 0.2750, 0.3223],\n",
      "         [0.3945, 0.4150, 0.2623,  ..., 0.2011, 0.6644, 0.3462],\n",
      "         [0.4337, 0.4123, 0.2221,  ..., 0.2194, 0.6747, 0.5077],\n",
      "         ...,\n",
      "         [0.6922, 0.6888, 0.7027,  ..., 0.7061, 0.5732, 0.5970],\n",
      "         [0.7294, 0.6981, 0.6955,  ..., 0.6727, 0.6353, 0.5497],\n",
      "         [0.6906, 0.6978, 0.7003,  ..., 0.6675, 0.7273, 0.5174]],\n",
      "\n",
      "        [[0.3566, 0.3987, 0.2436,  ..., 0.4228, 0.3231, 0.3751],\n",
      "         [0.4411, 0.4253, 0.2554,  ..., 0.2311, 0.7063, 0.4065],\n",
      "         [0.4915, 0.4351, 0.2182,  ..., 0.2317, 0.7125, 0.5704],\n",
      "         ...,\n",
      "         [0.6897, 0.6796, 0.6846,  ..., 0.7368, 0.6050, 0.6323],\n",
      "         [0.7254, 0.6825, 0.6759,  ..., 0.7001, 0.6510, 0.5854],\n",
      "         [0.6867, 0.6821, 0.6807,  ..., 0.6949, 0.7430, 0.5567]],\n",
      "\n",
      "        [[0.2864, 0.3163, 0.1612,  ..., 0.4161, 0.3517, 0.3923],\n",
      "         [0.3762, 0.3473, 0.1731,  ..., 0.1813, 0.7245, 0.4120],\n",
      "         [0.4438, 0.3624, 0.1358,  ..., 0.1139, 0.7089, 0.5668],\n",
      "         ...,\n",
      "         [0.5968, 0.5829, 0.5830,  ..., 0.6492, 0.5384, 0.6155],\n",
      "         [0.6078, 0.5687, 0.5622,  ..., 0.6296, 0.5843, 0.5715],\n",
      "         [0.5690, 0.5684, 0.5670,  ..., 0.6322, 0.6842, 0.5132]]])\n"
     ]
    }
   ],
   "source": [
    "data, label = test_dataset[3649]\n",
    "#print(len(train_dataset))\n",
    "print(labels[label])\n",
    "show((data))\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d844a044-20a7-4c4e-a5bc-9b0061d988bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataiter = iter(train_loader)\n",
    "# image, label = dataiter.next() # 返回8张图片及标签，因为之前封装的方法batch_size=8\n",
    "# image, label = image.to(device), label.to(device)\n",
    "# print(''.join('%11s'%labels[label[j]] for j in range(8)))\n",
    "# show(tv.utils.make_grid(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fe1fd6bc-e4c7-4129-875f-8b2dbef63c7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# mat1 and mat2 shapes cannot be multiplied (64x8192 and 2048x1024) (32x32768 and 2048x1024)\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        # input 維度 [3, 128, 128]\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, 1, 1),  # [64, 128, 128]\n",
    "           # nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0),      # [64, 64, 64] \n",
    " \n",
    "            nn.Conv2d(64, 128, 3, 1, 1), # [128, 64, 64] \n",
    "           # nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0),      # [128, 32, 32]\n",
    "\n",
    "            nn.Conv2d(128, 256, 3, 1, 1), # [256, 32, 32]\n",
    "          #  nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0),      # [256, 16, 16]\n",
    "\n",
    "            nn.Conv2d(256, 512, 3, 1, 1), # [512, 16, 16]\n",
    "          #  nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0),       # [512, 8, 8]\n",
    "            \n",
    "            nn.Conv2d(512, 512, 3, 1, 1), # [512, 8, 8]\n",
    "           # nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0),       # [512, 4, 4]\n",
    "            \n",
    "            nn.Conv2d(512, 512, 3, 1, 1), # [512, 8, 8]\n",
    "           # nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0),       # [512, 2, 2]\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(512*2*2, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 128), \n",
    "            nn.ReLU(), \n",
    "            nn.Linear(128,2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.cnn(x)\n",
    "        out = out.view(out.size()[0], -1)\n",
    "        return self.fc(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "24faa621-6333-44ff-86f1-2dec7ff16ba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier(\n",
       "  (cnn): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU()\n",
       "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (9): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (10): ReLU()\n",
       "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (12): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU()\n",
       "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (15): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (16): ReLU()\n",
       "    (17): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=128, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=128, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Classifier()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "905ec0d0-d1e1-423e-9a61-98d38952329d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1dc99203-90a0-441a-a974-efcb47591d80",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[001/002] 52.09 sec(s) Train Acc: 0.779533 Loss: 0.014438 | Val Acc: 0.809440 loss: 0.013229\n",
      "[002/002] 50.38 sec(s) Train Acc: 0.825133 Loss: 0.012021 | Val Acc: 0.834080 loss: 0.011399\n"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "for epoch in range(epochs):\n",
    "    epoch_start_time = time.time()\n",
    "    train_acc =0.0\n",
    "    val_acc =0.0\n",
    "    train_loss = 0.0\n",
    "    val_loss =0.0\n",
    "    model.train()\n",
    "    for i,data in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        image, label = data[0].to(device), data[1].to(device)\n",
    "        output = model(image)\n",
    "        \n",
    "        loss = criterion(output, label.long())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_acc += np.sum(np.argmax(output.cpu().data.numpy(),axis=1)== label.cpu().numpy())\n",
    "        train_loss +=loss.item()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i,data in enumerate(valid_loader):\n",
    "            valx ,valy = data[0].to(device),data[1].to(device)\n",
    "            val_pred = model(valx)\n",
    "            batch_loss = criterion(val_pred,valy.long())\n",
    "            val_acc +=np.sum(np.argmax(val_pred.cpu().data.numpy(),axis=1)== valy.cpu().numpy())\n",
    "            val_loss +=batch_loss.item()\n",
    "\n",
    "        print('[%03d/%03d] %2.2f sec(s) Train Acc: %3.6f Loss: %3.6f | Val Acc: %3.6f loss: %3.6f' % \\\n",
    "            (epoch + 1, epochs, time.time()-epoch_start_time, \\\n",
    "             train_acc/train_dataset.__len__(), train_loss/train_dataset.__len__(), val_acc/valid_dataset.__len__(), val_loss/valid_dataset.__len__()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f9f665-07aa-4b8d-a9dc-8fea995f47c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gluvyi",
   "language": "python",
   "name": "gluvyi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
